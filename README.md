# AghinyanLusineHW2

Bandit_Reward=[1,2,3,4] 
NumberOfTrials: 20000
Required Steps:
1. Create a Bandit Class
2. Create EpsilonGreedy() and ThompsonSampling() classes and methods (inherited
from Bandit()).
Epsilon-greedy Class:
1. decay epsilon by 1/t
2. design the experiment
Thompson Sampling Class:
1. design with known precision
2. 2. design the experiment
  
Final Steps:
Report:
1. Visualize the learning process for each algorithm (plot1())
2. Visualize cumulative rewards from E-Greedy and Thompson Sampling. 3. Store the rewards in a CSV file ({Bandit, Reward, Algorithm})
4. Print cumulative reward
5. Print cumulative regret
Note the values of epsilon and precision are up to you to decide.


BONUS
Suggest better implementation plan (10 points )

